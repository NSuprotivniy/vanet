{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "import pandas as pd\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.optimizers import Adam, RMSprop, SGD\n",
    "import sys, re, glob\n",
    "import numpy as np\n",
    "from keras.layers import Input, Dense, Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(folder, rng):\n",
    "    X = []\n",
    "\n",
    "    for i in range(rng):\n",
    "\n",
    "        packets = list()\n",
    "        max_node = 0\n",
    "        max_time = 0\n",
    "\n",
    "        for file in glob.glob(\"{}/output_{}/*.routes\".format(folder, i)):\n",
    "\n",
    "            handle = open(file, 'r')\n",
    "            data = handle.read()\n",
    "            handle.close()\n",
    "\n",
    "            _nodes = re.split('\\n\\n', data);\n",
    "\n",
    "            _nodes.pop()\n",
    "            for node in _nodes:\n",
    "\n",
    "                _strs = re.findall('(\\d{1,3}(?:\\.\\d{1,3}){3})\\s+\\d{1,3}(?:\\.\\d{1,3}){3}\\s+\\d{1,3}(?:\\.\\d{1,3}){3}\\s+\\w+\\s+-?\\d+\\.\\d+\\s+(\\d+)', node)\n",
    "\n",
    "                strings = list()\n",
    "                for _str in _strs:\n",
    "                    strings.append(dict(zip(('Destination', 'Hops'), _str)))\n",
    "\n",
    "                header = re.findall('Node:\\s+(\\d+)\\s+Time:\\s+(\\d+)', node)\n",
    "\n",
    "                max_node = max(max_node, int(header[0][0]))\n",
    "                max_time = max(max_time, int(header[0][1]))\n",
    "\n",
    "                for _str in strings:\n",
    "                    _str['Node'] = int(header[0][0])\n",
    "                    _str['Time'] = int(header[0][1])\n",
    "                    packets.append(_str)\n",
    "\n",
    "\n",
    "        table = pd.DataFrame(packets)\n",
    "        time_agg = table.groupby([\"Node\", \"Destination\"]).agg(['min', 'max', \"mean\", \"median\", \"prod\", \"sum\", \"std\", \"var\"])\n",
    "        node_agg = time_agg.groupby(\"Node\").agg(['min', 'max', \"mean\", \"median\", \"prod\", \"sum\", \"std\", \"var\"])\n",
    "        aggregate = node_agg.agg(['min', 'max', \"mean\", \"median\", \"prod\", \"sum\", \"std\", \"var\"])\n",
    "        X.append(aggregate.values.flatten())\n",
    "\n",
    "    X = np.array(X)\n",
    "    X[np.isnan(X) | np.isinf(X)] = 0\n",
    "    \n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "malicious = load_data(\"../data/malicious\", 100)\n",
    "normal = load_data(\"../data/normal\", 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHAPE = malicious.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPTIMIZER = Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(2048, input_shape=(1000,)))\n",
    "model.add(LeakyReLU(alpha=0.2))\n",
    "model.add(BatchNormalization(momentum=0.8))\n",
    "model.add(Dense(SHAPE, activation='sigmoid'))\n",
    "generator = model\n",
    "\n",
    "generator.compile(loss='binary_crossentropy', optimizer=OPTIMIZER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10, input_shape=(SHAPE,)))\n",
    "model.add(LeakyReLU(alpha=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "discriminator = model\n",
    "\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=OPTIMIZER, metrics=['accuracy'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.trainable = False\n",
    "model = Sequential()\n",
    "model.add(generator)\n",
    "model.add(discriminator)\n",
    "\n",
    "stacked = model\n",
    "stacked.compile(loss='binary_crossentropy', optimizer=OPTIMIZER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(malicious, normal, epochs=200, batch = 10):\n",
    "    for cnt in range(epochs):\n",
    "        \n",
    "        ## train discriminator\n",
    "        random_index =  np.random.randint(0, len(malicious) - batch)\n",
    "        malicious_sample = malicious[random_index : random_index + batch]\n",
    "        normal_sample = normal[random_index : random_index + batch]\n",
    "        \n",
    "        gen_noise = np.random.normal(0, 1, (batch,1000))\n",
    "        syntetic = generator.predict(gen_noise)\n",
    "        \n",
    "        x_combined_batch = np.concatenate((malicious_sample, normal_sample, syntetic))\n",
    "        y_combined_batch = np.concatenate((np.ones((batch, 1)), np.zeros((batch, 1)), np.zeros((batch, 1))))\n",
    "        \n",
    "        x_combined_batch =  np.clip(0.999, 0.001, x_combined_batch)\n",
    "        \n",
    "        d_loss = discriminator.train_on_batch(x_combined_batch, y_combined_batch)\n",
    "    \n",
    "        # train generator\n",
    "        noise = np.random.normal(0, 1, (batch,1000))\n",
    "        y_mislabled = np.ones((batch, 1))\n",
    "        g_loss = stacked.train_on_batch(noise, y_mislabled)\n",
    "        print ('epoch: %d, [Discriminator :: d_loss: %f], [ Generator :: loss: %f]' % (cnt, d_loss[0], g_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\надя\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, [Discriminator :: d_loss: 0.657597], [ Generator :: loss: 0.797228]\n",
      "epoch: 1, [Discriminator :: d_loss: 0.658840], [ Generator :: loss: 0.858241]\n",
      "epoch: 2, [Discriminator :: d_loss: 0.680956], [ Generator :: loss: 0.914900]\n",
      "epoch: 3, [Discriminator :: d_loss: 0.625542], [ Generator :: loss: 0.973440]\n",
      "epoch: 4, [Discriminator :: d_loss: 0.669429], [ Generator :: loss: 1.018024]\n",
      "epoch: 5, [Discriminator :: d_loss: 0.676260], [ Generator :: loss: 1.021305]\n",
      "epoch: 6, [Discriminator :: d_loss: 0.668776], [ Generator :: loss: 0.988320]\n",
      "epoch: 7, [Discriminator :: d_loss: 0.674336], [ Generator :: loss: 1.017800]\n",
      "epoch: 8, [Discriminator :: d_loss: 0.594389], [ Generator :: loss: 0.978336]\n",
      "epoch: 9, [Discriminator :: d_loss: 0.635980], [ Generator :: loss: 1.017622]\n",
      "epoch: 10, [Discriminator :: d_loss: 0.609270], [ Generator :: loss: 1.013893]\n",
      "epoch: 11, [Discriminator :: d_loss: 0.646099], [ Generator :: loss: 1.130640]\n",
      "epoch: 12, [Discriminator :: d_loss: 0.666278], [ Generator :: loss: 1.157950]\n",
      "epoch: 13, [Discriminator :: d_loss: 0.614064], [ Generator :: loss: 1.163423]\n",
      "epoch: 14, [Discriminator :: d_loss: 0.612299], [ Generator :: loss: 1.125169]\n",
      "epoch: 15, [Discriminator :: d_loss: 0.566760], [ Generator :: loss: 1.253751]\n",
      "epoch: 16, [Discriminator :: d_loss: 0.609956], [ Generator :: loss: 1.045160]\n",
      "epoch: 17, [Discriminator :: d_loss: 0.631048], [ Generator :: loss: 1.139943]\n",
      "epoch: 18, [Discriminator :: d_loss: 0.563433], [ Generator :: loss: 1.380731]\n",
      "epoch: 19, [Discriminator :: d_loss: 0.650751], [ Generator :: loss: 1.220134]\n",
      "epoch: 20, [Discriminator :: d_loss: 0.649444], [ Generator :: loss: 1.269023]\n",
      "epoch: 21, [Discriminator :: d_loss: 0.568994], [ Generator :: loss: 1.352973]\n",
      "epoch: 22, [Discriminator :: d_loss: 0.555905], [ Generator :: loss: 1.223610]\n",
      "epoch: 23, [Discriminator :: d_loss: 0.613506], [ Generator :: loss: 1.442216]\n",
      "epoch: 24, [Discriminator :: d_loss: 0.607724], [ Generator :: loss: 1.309786]\n",
      "epoch: 25, [Discriminator :: d_loss: 0.681603], [ Generator :: loss: 1.185975]\n",
      "epoch: 26, [Discriminator :: d_loss: 0.498032], [ Generator :: loss: 1.208604]\n",
      "epoch: 27, [Discriminator :: d_loss: 0.608338], [ Generator :: loss: 1.425486]\n",
      "epoch: 28, [Discriminator :: d_loss: 0.636792], [ Generator :: loss: 1.326373]\n",
      "epoch: 29, [Discriminator :: d_loss: 0.720721], [ Generator :: loss: 1.316335]\n",
      "epoch: 30, [Discriminator :: d_loss: 0.641063], [ Generator :: loss: 1.549592]\n",
      "epoch: 31, [Discriminator :: d_loss: 0.630844], [ Generator :: loss: 1.681435]\n",
      "epoch: 32, [Discriminator :: d_loss: 0.557011], [ Generator :: loss: 1.569832]\n",
      "epoch: 33, [Discriminator :: d_loss: 0.607403], [ Generator :: loss: 1.336006]\n",
      "epoch: 34, [Discriminator :: d_loss: 0.615737], [ Generator :: loss: 1.598394]\n",
      "epoch: 35, [Discriminator :: d_loss: 0.592697], [ Generator :: loss: 1.417373]\n",
      "epoch: 36, [Discriminator :: d_loss: 0.506642], [ Generator :: loss: 1.941253]\n",
      "epoch: 37, [Discriminator :: d_loss: 0.608863], [ Generator :: loss: 1.605954]\n",
      "epoch: 38, [Discriminator :: d_loss: 0.635523], [ Generator :: loss: 1.886052]\n",
      "epoch: 39, [Discriminator :: d_loss: 0.591411], [ Generator :: loss: 1.940803]\n",
      "epoch: 40, [Discriminator :: d_loss: 0.540976], [ Generator :: loss: 1.937093]\n",
      "epoch: 41, [Discriminator :: d_loss: 0.564591], [ Generator :: loss: 1.974832]\n",
      "epoch: 42, [Discriminator :: d_loss: 0.592020], [ Generator :: loss: 1.711343]\n",
      "epoch: 43, [Discriminator :: d_loss: 0.639361], [ Generator :: loss: 1.774866]\n",
      "epoch: 44, [Discriminator :: d_loss: 0.703011], [ Generator :: loss: 1.798592]\n",
      "epoch: 45, [Discriminator :: d_loss: 0.562628], [ Generator :: loss: 1.869213]\n",
      "epoch: 46, [Discriminator :: d_loss: 0.616302], [ Generator :: loss: 1.604815]\n",
      "epoch: 47, [Discriminator :: d_loss: 0.583861], [ Generator :: loss: 2.195592]\n",
      "epoch: 48, [Discriminator :: d_loss: 0.641054], [ Generator :: loss: 2.055550]\n",
      "epoch: 49, [Discriminator :: d_loss: 0.607664], [ Generator :: loss: 1.712671]\n",
      "epoch: 50, [Discriminator :: d_loss: 0.763085], [ Generator :: loss: 1.865745]\n",
      "epoch: 51, [Discriminator :: d_loss: 0.552945], [ Generator :: loss: 1.964156]\n",
      "epoch: 52, [Discriminator :: d_loss: 0.507405], [ Generator :: loss: 1.962162]\n",
      "epoch: 53, [Discriminator :: d_loss: 0.606737], [ Generator :: loss: 2.787896]\n",
      "epoch: 54, [Discriminator :: d_loss: 0.614619], [ Generator :: loss: 2.425287]\n",
      "epoch: 55, [Discriminator :: d_loss: 0.537771], [ Generator :: loss: 2.730827]\n",
      "epoch: 56, [Discriminator :: d_loss: 0.601273], [ Generator :: loss: 2.551838]\n",
      "epoch: 57, [Discriminator :: d_loss: 0.706022], [ Generator :: loss: 2.211002]\n",
      "epoch: 58, [Discriminator :: d_loss: 0.538474], [ Generator :: loss: 2.446925]\n",
      "epoch: 59, [Discriminator :: d_loss: 0.540697], [ Generator :: loss: 2.065484]\n",
      "epoch: 60, [Discriminator :: d_loss: 0.608975], [ Generator :: loss: 2.129460]\n",
      "epoch: 61, [Discriminator :: d_loss: 0.618056], [ Generator :: loss: 2.422364]\n",
      "epoch: 62, [Discriminator :: d_loss: 0.552975], [ Generator :: loss: 2.400314]\n",
      "epoch: 63, [Discriminator :: d_loss: 0.531494], [ Generator :: loss: 2.229148]\n",
      "epoch: 64, [Discriminator :: d_loss: 0.550447], [ Generator :: loss: 2.388386]\n",
      "epoch: 65, [Discriminator :: d_loss: 0.617444], [ Generator :: loss: 2.597786]\n",
      "epoch: 66, [Discriminator :: d_loss: 0.485791], [ Generator :: loss: 2.114658]\n",
      "epoch: 67, [Discriminator :: d_loss: 0.592841], [ Generator :: loss: 1.996487]\n",
      "epoch: 68, [Discriminator :: d_loss: 0.564326], [ Generator :: loss: 2.707109]\n",
      "epoch: 69, [Discriminator :: d_loss: 0.478710], [ Generator :: loss: 2.730328]\n",
      "epoch: 70, [Discriminator :: d_loss: 0.626931], [ Generator :: loss: 2.671474]\n",
      "epoch: 71, [Discriminator :: d_loss: 0.532361], [ Generator :: loss: 2.310267]\n",
      "epoch: 72, [Discriminator :: d_loss: 0.542132], [ Generator :: loss: 2.655252]\n",
      "epoch: 73, [Discriminator :: d_loss: 0.495259], [ Generator :: loss: 2.743173]\n",
      "epoch: 74, [Discriminator :: d_loss: 0.617084], [ Generator :: loss: 2.696194]\n",
      "epoch: 75, [Discriminator :: d_loss: 0.540292], [ Generator :: loss: 2.610260]\n",
      "epoch: 76, [Discriminator :: d_loss: 0.563991], [ Generator :: loss: 2.359402]\n",
      "epoch: 77, [Discriminator :: d_loss: 0.537496], [ Generator :: loss: 2.168310]\n",
      "epoch: 78, [Discriminator :: d_loss: 0.550207], [ Generator :: loss: 2.393369]\n",
      "epoch: 79, [Discriminator :: d_loss: 0.531829], [ Generator :: loss: 3.052536]\n",
      "epoch: 80, [Discriminator :: d_loss: 0.491460], [ Generator :: loss: 2.758200]\n",
      "epoch: 81, [Discriminator :: d_loss: 0.551482], [ Generator :: loss: 1.973530]\n",
      "epoch: 82, [Discriminator :: d_loss: 0.488756], [ Generator :: loss: 2.962774]\n",
      "epoch: 83, [Discriminator :: d_loss: 0.569087], [ Generator :: loss: 2.236596]\n",
      "epoch: 84, [Discriminator :: d_loss: 0.612630], [ Generator :: loss: 2.755676]\n",
      "epoch: 85, [Discriminator :: d_loss: 0.494006], [ Generator :: loss: 2.463905]\n",
      "epoch: 86, [Discriminator :: d_loss: 0.499202], [ Generator :: loss: 2.292377]\n",
      "epoch: 87, [Discriminator :: d_loss: 0.491292], [ Generator :: loss: 2.065275]\n",
      "epoch: 88, [Discriminator :: d_loss: 0.530945], [ Generator :: loss: 3.027574]\n",
      "epoch: 89, [Discriminator :: d_loss: 0.498376], [ Generator :: loss: 2.332394]\n",
      "epoch: 90, [Discriminator :: d_loss: 0.520203], [ Generator :: loss: 3.233615]\n",
      "epoch: 91, [Discriminator :: d_loss: 0.598992], [ Generator :: loss: 2.500990]\n",
      "epoch: 92, [Discriminator :: d_loss: 0.527339], [ Generator :: loss: 2.803034]\n",
      "epoch: 93, [Discriminator :: d_loss: 0.508680], [ Generator :: loss: 2.559363]\n",
      "epoch: 94, [Discriminator :: d_loss: 0.612092], [ Generator :: loss: 2.344073]\n",
      "epoch: 95, [Discriminator :: d_loss: 0.503957], [ Generator :: loss: 2.626557]\n",
      "epoch: 96, [Discriminator :: d_loss: 0.552954], [ Generator :: loss: 2.209519]\n",
      "epoch: 97, [Discriminator :: d_loss: 0.458246], [ Generator :: loss: 2.644620]\n",
      "epoch: 98, [Discriminator :: d_loss: 0.566092], [ Generator :: loss: 2.947198]\n",
      "epoch: 99, [Discriminator :: d_loss: 0.550910], [ Generator :: loss: 2.857831]\n",
      "epoch: 100, [Discriminator :: d_loss: 0.512959], [ Generator :: loss: 2.455714]\n",
      "epoch: 101, [Discriminator :: d_loss: 0.490674], [ Generator :: loss: 3.328403]\n",
      "epoch: 102, [Discriminator :: d_loss: 0.514536], [ Generator :: loss: 2.880847]\n",
      "epoch: 103, [Discriminator :: d_loss: 0.610237], [ Generator :: loss: 2.615805]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 104, [Discriminator :: d_loss: 0.560482], [ Generator :: loss: 2.454636]\n",
      "epoch: 105, [Discriminator :: d_loss: 0.517468], [ Generator :: loss: 2.782527]\n",
      "epoch: 106, [Discriminator :: d_loss: 0.546222], [ Generator :: loss: 2.581967]\n",
      "epoch: 107, [Discriminator :: d_loss: 0.537832], [ Generator :: loss: 2.565624]\n",
      "epoch: 108, [Discriminator :: d_loss: 0.550273], [ Generator :: loss: 3.049834]\n",
      "epoch: 109, [Discriminator :: d_loss: 0.518208], [ Generator :: loss: 3.101372]\n",
      "epoch: 110, [Discriminator :: d_loss: 0.503674], [ Generator :: loss: 3.312922]\n",
      "epoch: 111, [Discriminator :: d_loss: 0.605421], [ Generator :: loss: 2.267428]\n",
      "epoch: 112, [Discriminator :: d_loss: 0.562114], [ Generator :: loss: 2.201267]\n",
      "epoch: 113, [Discriminator :: d_loss: 0.496349], [ Generator :: loss: 2.728185]\n",
      "epoch: 114, [Discriminator :: d_loss: 0.573618], [ Generator :: loss: 3.002558]\n",
      "epoch: 115, [Discriminator :: d_loss: 0.486390], [ Generator :: loss: 2.314615]\n",
      "epoch: 116, [Discriminator :: d_loss: 0.465667], [ Generator :: loss: 3.004881]\n",
      "epoch: 117, [Discriminator :: d_loss: 0.421687], [ Generator :: loss: 3.003796]\n",
      "epoch: 118, [Discriminator :: d_loss: 0.470722], [ Generator :: loss: 2.164433]\n",
      "epoch: 119, [Discriminator :: d_loss: 0.462917], [ Generator :: loss: 2.144494]\n",
      "epoch: 120, [Discriminator :: d_loss: 0.541664], [ Generator :: loss: 1.720537]\n",
      "epoch: 121, [Discriminator :: d_loss: 0.631532], [ Generator :: loss: 1.877925]\n",
      "epoch: 122, [Discriminator :: d_loss: 0.453252], [ Generator :: loss: 2.114217]\n",
      "epoch: 123, [Discriminator :: d_loss: 0.579898], [ Generator :: loss: 2.806506]\n",
      "epoch: 124, [Discriminator :: d_loss: 0.543745], [ Generator :: loss: 2.139806]\n",
      "epoch: 125, [Discriminator :: d_loss: 0.574664], [ Generator :: loss: 3.487412]\n",
      "epoch: 126, [Discriminator :: d_loss: 0.504279], [ Generator :: loss: 3.564878]\n",
      "epoch: 127, [Discriminator :: d_loss: 0.512706], [ Generator :: loss: 2.637578]\n",
      "epoch: 128, [Discriminator :: d_loss: 0.541559], [ Generator :: loss: 2.505442]\n",
      "epoch: 129, [Discriminator :: d_loss: 0.549577], [ Generator :: loss: 2.482079]\n",
      "epoch: 130, [Discriminator :: d_loss: 0.432487], [ Generator :: loss: 2.424950]\n",
      "epoch: 131, [Discriminator :: d_loss: 0.582428], [ Generator :: loss: 2.966671]\n",
      "epoch: 132, [Discriminator :: d_loss: 0.522845], [ Generator :: loss: 1.905716]\n",
      "epoch: 133, [Discriminator :: d_loss: 0.497542], [ Generator :: loss: 2.722372]\n",
      "epoch: 134, [Discriminator :: d_loss: 0.552533], [ Generator :: loss: 2.279317]\n",
      "epoch: 135, [Discriminator :: d_loss: 0.572353], [ Generator :: loss: 2.015775]\n",
      "epoch: 136, [Discriminator :: d_loss: 0.548838], [ Generator :: loss: 2.728764]\n",
      "epoch: 137, [Discriminator :: d_loss: 0.556756], [ Generator :: loss: 2.788588]\n",
      "epoch: 138, [Discriminator :: d_loss: 0.545603], [ Generator :: loss: 3.086597]\n",
      "epoch: 139, [Discriminator :: d_loss: 0.580668], [ Generator :: loss: 2.010339]\n",
      "epoch: 140, [Discriminator :: d_loss: 0.494236], [ Generator :: loss: 1.905848]\n",
      "epoch: 141, [Discriminator :: d_loss: 0.619425], [ Generator :: loss: 1.876073]\n",
      "epoch: 142, [Discriminator :: d_loss: 0.560449], [ Generator :: loss: 2.533395]\n",
      "epoch: 143, [Discriminator :: d_loss: 0.546990], [ Generator :: loss: 2.138082]\n",
      "epoch: 144, [Discriminator :: d_loss: 0.444085], [ Generator :: loss: 2.037827]\n",
      "epoch: 145, [Discriminator :: d_loss: 0.542546], [ Generator :: loss: 2.082664]\n",
      "epoch: 146, [Discriminator :: d_loss: 0.570031], [ Generator :: loss: 1.900419]\n",
      "epoch: 147, [Discriminator :: d_loss: 0.550949], [ Generator :: loss: 2.596280]\n",
      "epoch: 148, [Discriminator :: d_loss: 0.592094], [ Generator :: loss: 1.937092]\n",
      "epoch: 149, [Discriminator :: d_loss: 0.601251], [ Generator :: loss: 2.178313]\n",
      "epoch: 150, [Discriminator :: d_loss: 0.609434], [ Generator :: loss: 2.507496]\n",
      "epoch: 151, [Discriminator :: d_loss: 0.601140], [ Generator :: loss: 1.405418]\n",
      "epoch: 152, [Discriminator :: d_loss: 0.660536], [ Generator :: loss: 1.735554]\n",
      "epoch: 153, [Discriminator :: d_loss: 0.535290], [ Generator :: loss: 2.006803]\n",
      "epoch: 154, [Discriminator :: d_loss: 0.564114], [ Generator :: loss: 1.837193]\n",
      "epoch: 155, [Discriminator :: d_loss: 0.598799], [ Generator :: loss: 2.107120]\n",
      "epoch: 156, [Discriminator :: d_loss: 0.595917], [ Generator :: loss: 2.072737]\n",
      "epoch: 157, [Discriminator :: d_loss: 0.637050], [ Generator :: loss: 2.383746]\n",
      "epoch: 158, [Discriminator :: d_loss: 0.557514], [ Generator :: loss: 1.501076]\n",
      "epoch: 159, [Discriminator :: d_loss: 0.579043], [ Generator :: loss: 1.756338]\n",
      "epoch: 160, [Discriminator :: d_loss: 0.542635], [ Generator :: loss: 2.334127]\n",
      "epoch: 161, [Discriminator :: d_loss: 0.588569], [ Generator :: loss: 3.136669]\n",
      "epoch: 162, [Discriminator :: d_loss: 0.602527], [ Generator :: loss: 1.236706]\n",
      "epoch: 163, [Discriminator :: d_loss: 0.584984], [ Generator :: loss: 2.223780]\n",
      "epoch: 164, [Discriminator :: d_loss: 0.549035], [ Generator :: loss: 1.506055]\n",
      "epoch: 165, [Discriminator :: d_loss: 0.647332], [ Generator :: loss: 2.128420]\n",
      "epoch: 166, [Discriminator :: d_loss: 0.554544], [ Generator :: loss: 2.246435]\n",
      "epoch: 167, [Discriminator :: d_loss: 0.555668], [ Generator :: loss: 1.338581]\n",
      "epoch: 168, [Discriminator :: d_loss: 0.591749], [ Generator :: loss: 1.934834]\n",
      "epoch: 169, [Discriminator :: d_loss: 0.513711], [ Generator :: loss: 2.945078]\n",
      "epoch: 170, [Discriminator :: d_loss: 0.593736], [ Generator :: loss: 1.522803]\n",
      "epoch: 171, [Discriminator :: d_loss: 0.550010], [ Generator :: loss: 2.487583]\n",
      "epoch: 172, [Discriminator :: d_loss: 0.491387], [ Generator :: loss: 2.509057]\n",
      "epoch: 173, [Discriminator :: d_loss: 0.550301], [ Generator :: loss: 2.016336]\n",
      "epoch: 174, [Discriminator :: d_loss: 0.577988], [ Generator :: loss: 2.515747]\n",
      "epoch: 175, [Discriminator :: d_loss: 0.583937], [ Generator :: loss: 1.887356]\n",
      "epoch: 176, [Discriminator :: d_loss: 0.564079], [ Generator :: loss: 2.346510]\n",
      "epoch: 177, [Discriminator :: d_loss: 0.560155], [ Generator :: loss: 2.120842]\n",
      "epoch: 178, [Discriminator :: d_loss: 0.517681], [ Generator :: loss: 1.875109]\n",
      "epoch: 179, [Discriminator :: d_loss: 0.583400], [ Generator :: loss: 1.597717]\n",
      "epoch: 180, [Discriminator :: d_loss: 0.540010], [ Generator :: loss: 2.386292]\n",
      "epoch: 181, [Discriminator :: d_loss: 0.532817], [ Generator :: loss: 1.672474]\n",
      "epoch: 182, [Discriminator :: d_loss: 0.528749], [ Generator :: loss: 2.056542]\n",
      "epoch: 183, [Discriminator :: d_loss: 0.542359], [ Generator :: loss: 1.824572]\n",
      "epoch: 184, [Discriminator :: d_loss: 0.497523], [ Generator :: loss: 1.741843]\n",
      "epoch: 185, [Discriminator :: d_loss: 0.529756], [ Generator :: loss: 1.605791]\n",
      "epoch: 186, [Discriminator :: d_loss: 0.548324], [ Generator :: loss: 2.567226]\n",
      "epoch: 187, [Discriminator :: d_loss: 0.544885], [ Generator :: loss: 1.925756]\n",
      "epoch: 188, [Discriminator :: d_loss: 0.570147], [ Generator :: loss: 1.764549]\n",
      "epoch: 189, [Discriminator :: d_loss: 0.599031], [ Generator :: loss: 1.307690]\n",
      "epoch: 190, [Discriminator :: d_loss: 0.510985], [ Generator :: loss: 1.664101]\n",
      "epoch: 191, [Discriminator :: d_loss: 0.544634], [ Generator :: loss: 1.883463]\n",
      "epoch: 192, [Discriminator :: d_loss: 0.581344], [ Generator :: loss: 1.900971]\n",
      "epoch: 193, [Discriminator :: d_loss: 0.538995], [ Generator :: loss: 2.072791]\n",
      "epoch: 194, [Discriminator :: d_loss: 0.605487], [ Generator :: loss: 1.932500]\n",
      "epoch: 195, [Discriminator :: d_loss: 0.548134], [ Generator :: loss: 1.512166]\n",
      "epoch: 196, [Discriminator :: d_loss: 0.586019], [ Generator :: loss: 2.048096]\n",
      "epoch: 197, [Discriminator :: d_loss: 0.554493], [ Generator :: loss: 1.395878]\n",
      "epoch: 198, [Discriminator :: d_loss: 0.540933], [ Generator :: loss: 1.859670]\n",
      "epoch: 199, [Discriminator :: d_loss: 0.524677], [ Generator :: loss: 1.491047]\n"
     ]
    }
   ],
   "source": [
    "train(malicious, normal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preidiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.clip(0.999, 0.001,np.concatenate((malicious, normal)))\n",
    "y = np.concatenate((np.ones((100, 1)), np.zeros((100, 1))))\n",
    "predict = discriminator.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.4668372 , 0.45773798, 0.44985774, 0.2925268 , 0.45053574,\n",
       "       0.41617912, 0.48971727, 0.48742008, 0.52487576, 0.51916504,\n",
       "       0.48437524, 0.4228453 , 0.47369644, 0.39084658, 0.39240673,\n",
       "       0.4641969 , 0.36108044, 0.5166242 , 0.47687906, 0.4590735 ,\n",
       "       0.47936973, 0.46695462, 0.35361037, 0.5313895 , 0.507049  ,\n",
       "       0.5135777 , 0.5268032 , 0.46588784, 0.483805  , 0.47695303,\n",
       "       0.4760999 , 0.4343862 , 0.4605973 , 0.44013572, 0.41303518,\n",
       "       0.49984413, 0.4312235 , 0.5269966 , 0.53654945, 0.4676903 ,\n",
       "       0.52233857, 0.36657742, 0.4867758 , 0.49604565, 0.44467506,\n",
       "       0.45084584, 0.5085935 , 0.49166337, 0.40102258, 0.38977093,\n",
       "       0.46402362, 0.45272848, 0.44620302, 0.42671612, 0.4327435 ,\n",
       "       0.491731  , 0.3542246 , 0.44428584, 0.5212175 , 0.48889688,\n",
       "       0.5161691 , 0.5333095 , 0.5251244 , 0.404236  , 0.3903652 ,\n",
       "       0.36498177, 0.46116418, 0.41745064, 0.5202115 , 0.46057412,\n",
       "       0.5273734 , 0.45534945, 0.51566154, 0.48419452, 0.43622097,\n",
       "       0.50212425, 0.49724507, 0.4275775 , 0.3960573 , 0.5123575 ,\n",
       "       0.51124185, 0.46449116, 0.5344627 , 0.39438173, 0.52458537,\n",
       "       0.5166953 , 0.52010304, 0.51726586, 0.47256985, 0.44462427,\n",
       "       0.49137387, 0.5399475 , 0.48895884, 0.424422  , 0.32296982,\n",
       "       0.46579033, 0.4083111 , 0.5059037 , 0.40516174, 0.3942459 ,\n",
       "       0.4717976 , 0.39245975, 0.43454275, 0.47492668, 0.53970957,\n",
       "       0.39528105, 0.36337322, 0.3860494 , 0.36184606, 0.3985408 ,\n",
       "       0.34851712, 0.39297524, 0.39401022, 0.34881765, 0.3921985 ,\n",
       "       0.5080306 , 0.41906807, 0.3646067 , 0.46090484, 0.38601875,\n",
       "       0.41528806, 0.42976588, 0.43813097, 0.4401391 , 0.44824302,\n",
       "       0.4025468 , 0.38334638, 0.38282073, 0.27741048, 0.3848324 ,\n",
       "       0.38797772, 0.40636712, 0.39920378, 0.32092702, 0.44612643,\n",
       "       0.3192604 , 0.22870454, 0.37227196, 0.5196215 , 0.4040144 ,\n",
       "       0.3686499 , 0.40513873, 0.37273115, 0.3861553 , 0.43271938,\n",
       "       0.51424295, 0.4280943 , 0.4247249 , 0.4722005 , 0.35182396,\n",
       "       0.40700495, 0.47823438, 0.38441   , 0.34773532, 0.5005358 ,\n",
       "       0.51044804, 0.51357645, 0.4188318 , 0.3896391 , 0.31822875,\n",
       "       0.50559574, 0.51739776, 0.50154245, 0.31630206, 0.34637478,\n",
       "       0.37187582, 0.4074678 , 0.36255056, 0.48663068, 0.51111335,\n",
       "       0.32794538, 0.3336133 , 0.38599285, 0.43536347, 0.37661162,\n",
       "       0.49262965, 0.40131155, 0.4241821 , 0.4114802 , 0.48363435,\n",
       "       0.34493995, 0.5177461 , 0.34535408, 0.37912062, 0.42486492,\n",
       "       0.38838214, 0.35179743, 0.4991654 , 0.37935045, 0.38559937,\n",
       "       0.37924513, 0.36854446, 0.3866801 , 0.39485547, 0.3666949 ,\n",
       "       0.40000463, 0.44071004, 0.359562  , 0.3425906 , 0.44440997],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.58"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y == (predict > 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics​"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[88 12]\n",
      " [72 28]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.confusion_matrix(y, (predict > 0.5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malicious       0.55      0.88      0.68       100\n",
      "      normal       0.70      0.28      0.40       100\n",
      "\n",
      "   micro avg       0.58      0.58      0.58       200\n",
      "   macro avg       0.62      0.58      0.54       200\n",
      "weighted avg       0.62      0.58      0.54       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y, (predict>0.5), target_names=[\"malicious\", \"normal\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.58"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y, (predict > 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "If no scoring is specified, the estimator passed should have a 'score' method. The estimator <keras.engine.sequential.Sequential object at 0x0000023A2A519AC8> does not.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-9285eff58ebf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\надя\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    392\u001b[0m     \"\"\"\n\u001b[0;32m    393\u001b[0m     \u001b[1;31m# To ensure multimetric format is not supported\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 394\u001b[1;33m     \u001b[0mscorer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m     cv_results = cross_validate(estimator=estimator, X=X, y=y, groups=groups,\n",
      "\u001b[1;32mc:\\users\\надя\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\scorer.py\u001b[0m in \u001b[0;36mcheck_scoring\u001b[1;34m(estimator, scoring, allow_none)\u001b[0m\n\u001b[0;32m    281\u001b[0m                 \u001b[1;34m\"If no scoring is specified, the estimator passed should \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m                 \u001b[1;34m\"have a 'score' method. The estimator %r does not.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 283\u001b[1;33m                 % estimator)\n\u001b[0m\u001b[0;32m    284\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIterable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m         raise ValueError(\"For evaluating multiple scores, use \"\n",
      "\u001b[1;31mTypeError\u001b[0m: If no scoring is specified, the estimator passed should have a 'score' method. The estimator <keras.engine.sequential.Sequential object at 0x0000023A2A519AC8> does not."
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "# fix random seed for reproducibility\n",
    "seed = 5\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "# define 10-fold cross validation test harness\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "cvscores = []\n",
    "for train, test in kfold.split(X, Y):\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\t# Fit the model\n",
    "\tmodel.fit(X[train], Y[train], epochs=150, batch_size=10, verbose=0)\n",
    "\t# evaluate the model\n",
    "\tscores = model.evaluate(X[test], Y[test], verbose=0)\n",
    "\tprint(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "\tcvscores.append(scores[1] * 100)\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (numpy.mean(cvscores), numpy.std(cvscores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
