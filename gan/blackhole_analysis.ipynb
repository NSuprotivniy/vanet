{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nsuprotivniy/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "import pandas as pd\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.optimizers import Adam, RMSprop, SGD\n",
    "import sys, re, glob\n",
    "import numpy as np\n",
    "from keras.layers import Input, Dense, Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(folder, rng):\n",
    "    X = []\n",
    "\n",
    "    for i in range(rng):\n",
    "\n",
    "        packets = list()\n",
    "        max_node = 0\n",
    "        max_time = 0\n",
    "\n",
    "        for file in glob.glob(\"{}/output_{}/*.routes\".format(folder, i)):\n",
    "\n",
    "            handle = open(file, 'r')\n",
    "            data = handle.read()\n",
    "            handle.close()\n",
    "\n",
    "            _nodes = re.split('\\n\\n', data);\n",
    "\n",
    "            _nodes.pop()\n",
    "            for node in _nodes:\n",
    "\n",
    "                _strs = re.findall('(\\d{1,3}(?:\\.\\d{1,3}){3})\\s+\\d{1,3}(?:\\.\\d{1,3}){3}\\s+\\d{1,3}(?:\\.\\d{1,3}){3}\\s+\\w+\\s+-?\\d+\\.\\d+\\s+(\\d+)', node)\n",
    "\n",
    "                strings = list()\n",
    "                for _str in _strs:\n",
    "                    strings.append(dict(zip(('Destination', 'Hops'), _str)))\n",
    "\n",
    "                header = re.findall('Node:\\s+(\\d+)\\s+Time:\\s+(\\d+)', node)\n",
    "\n",
    "                max_node = max(max_node, int(header[0][0]))\n",
    "                max_time = max(max_time, int(header[0][1]))\n",
    "\n",
    "                for _str in strings:\n",
    "                    _str['Node'] = int(header[0][0])\n",
    "                    _str['Time'] = int(header[0][1])\n",
    "                    packets.append(_str)\n",
    "\n",
    "\n",
    "        table = pd.DataFrame(packets)\n",
    "        time_agg = table.groupby([\"Node\", \"Destination\"]).agg(['min', 'max', \"mean\", \"median\", \"prod\", \"sum\", \"std\", \"var\"])\n",
    "        node_agg = time_agg.groupby(\"Node\").agg(['min', 'max', \"mean\", \"median\", \"prod\", \"sum\", \"std\", \"var\"])\n",
    "        aggregate = node_agg.agg(['min', 'max', \"mean\", \"median\", \"prod\", \"sum\", \"std\", \"var\"])\n",
    "        X.append(aggregate.values.flatten())\n",
    "\n",
    "    X = np.array(X)\n",
    "    X[np.isnan(X) | np.isinf(X)] = 0\n",
    "    \n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "malicious = load_data(\"../data/malicious\", 100)\n",
    "normal = load_data(\"../data/normal\", 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHAPE = malicious.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPTIMIZER = Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(2048, input_shape=(1000,)))\n",
    "model.add(LeakyReLU(alpha=0.2))\n",
    "model.add(BatchNormalization(momentum=0.8))\n",
    "model.add(Dense(SHAPE, activation='sigmoid'))\n",
    "generator = model\n",
    "\n",
    "generator.compile(loss='binary_crossentropy', optimizer=OPTIMIZER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10, input_shape=(SHAPE,)))\n",
    "model.add(LeakyReLU(alpha=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "discriminator = model\n",
    "\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=OPTIMIZER, metrics=['accuracy'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.trainable = False\n",
    "model = Sequential()\n",
    "model.add(generator)\n",
    "model.add(discriminator)\n",
    "\n",
    "stacked = model\n",
    "stacked.compile(loss='binary_crossentropy', optimizer=OPTIMIZER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(malicious, normal, epochs=200, batch = 10):\n",
    "    for cnt in range(epochs):\n",
    "        \n",
    "        ## train discriminator\n",
    "        random_index =  np.random.randint(0, len(malicious) - batch)\n",
    "        malicious_sample = malicious[random_index : random_index + batch]\n",
    "        normal_sample = normal[random_index : random_index + batch]\n",
    "        \n",
    "        gen_noise = np.random.normal(0, 1, (batch,1000))\n",
    "        syntetic = generator.predict(gen_noise)\n",
    "        \n",
    "        x_combined_batch = np.concatenate((malicious_sample, normal_sample, syntetic))\n",
    "        y_combined_batch = np.concatenate((np.ones((batch, 1)), np.zeros((batch, 1)), np.zeros((batch, 1))))\n",
    "        \n",
    "        x_combined_batch =  np.clip(0.999, 0.001, x_combined_batch)\n",
    "        \n",
    "        d_loss = discriminator.train_on_batch(x_combined_batch, y_combined_batch)\n",
    "    \n",
    "        # train generator\n",
    "        noise = np.random.normal(0, 1, (batch,1000))\n",
    "        y_mislabled = np.ones((batch, 1))\n",
    "        g_loss = stacked.train_on_batch(noise, y_mislabled)\n",
    "        print ('epoch: %d, [Discriminator :: d_loss: %f], [ Generator :: loss: %f]' % (cnt, d_loss[0], g_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nsuprotivniy/anaconda3/lib/python3.6/site-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, [Discriminator :: d_loss: 0.924518], [ Generator :: loss: 0.588799]\n",
      "epoch: 1, [Discriminator :: d_loss: 0.820769], [ Generator :: loss: 0.733534]\n",
      "epoch: 2, [Discriminator :: d_loss: 0.705780], [ Generator :: loss: 0.827833]\n",
      "epoch: 3, [Discriminator :: d_loss: 0.664807], [ Generator :: loss: 0.970326]\n",
      "epoch: 4, [Discriminator :: d_loss: 0.681246], [ Generator :: loss: 0.996867]\n",
      "epoch: 5, [Discriminator :: d_loss: 0.683362], [ Generator :: loss: 1.068430]\n",
      "epoch: 6, [Discriminator :: d_loss: 0.722818], [ Generator :: loss: 1.119182]\n",
      "epoch: 7, [Discriminator :: d_loss: 0.715819], [ Generator :: loss: 1.104407]\n",
      "epoch: 8, [Discriminator :: d_loss: 0.703380], [ Generator :: loss: 1.104931]\n",
      "epoch: 9, [Discriminator :: d_loss: 0.699541], [ Generator :: loss: 1.077045]\n",
      "epoch: 10, [Discriminator :: d_loss: 0.683308], [ Generator :: loss: 0.969240]\n",
      "epoch: 11, [Discriminator :: d_loss: 0.678748], [ Generator :: loss: 1.026698]\n",
      "epoch: 12, [Discriminator :: d_loss: 0.698977], [ Generator :: loss: 0.943571]\n",
      "epoch: 13, [Discriminator :: d_loss: 0.651150], [ Generator :: loss: 0.834597]\n",
      "epoch: 14, [Discriminator :: d_loss: 0.672969], [ Generator :: loss: 0.935134]\n",
      "epoch: 15, [Discriminator :: d_loss: 0.708898], [ Generator :: loss: 0.865296]\n",
      "epoch: 16, [Discriminator :: d_loss: 0.805379], [ Generator :: loss: 0.812345]\n",
      "epoch: 17, [Discriminator :: d_loss: 0.685522], [ Generator :: loss: 0.852386]\n",
      "epoch: 18, [Discriminator :: d_loss: 0.822086], [ Generator :: loss: 0.866070]\n",
      "epoch: 19, [Discriminator :: d_loss: 0.761947], [ Generator :: loss: 0.859845]\n",
      "epoch: 20, [Discriminator :: d_loss: 0.654159], [ Generator :: loss: 0.790450]\n",
      "epoch: 21, [Discriminator :: d_loss: 0.721584], [ Generator :: loss: 0.815744]\n",
      "epoch: 22, [Discriminator :: d_loss: 0.808365], [ Generator :: loss: 0.763456]\n",
      "epoch: 23, [Discriminator :: d_loss: 0.636784], [ Generator :: loss: 0.812145]\n",
      "epoch: 24, [Discriminator :: d_loss: 0.672650], [ Generator :: loss: 1.033615]\n",
      "epoch: 25, [Discriminator :: d_loss: 0.786493], [ Generator :: loss: 0.942502]\n",
      "epoch: 26, [Discriminator :: d_loss: 0.797782], [ Generator :: loss: 0.933937]\n",
      "epoch: 27, [Discriminator :: d_loss: 0.821479], [ Generator :: loss: 0.873760]\n",
      "epoch: 28, [Discriminator :: d_loss: 0.860888], [ Generator :: loss: 1.029304]\n",
      "epoch: 29, [Discriminator :: d_loss: 0.870519], [ Generator :: loss: 1.268500]\n",
      "epoch: 30, [Discriminator :: d_loss: 0.986875], [ Generator :: loss: 0.839627]\n",
      "epoch: 31, [Discriminator :: d_loss: 0.796646], [ Generator :: loss: 1.161682]\n",
      "epoch: 32, [Discriminator :: d_loss: 0.847529], [ Generator :: loss: 1.022788]\n",
      "epoch: 33, [Discriminator :: d_loss: 0.773814], [ Generator :: loss: 1.169822]\n",
      "epoch: 34, [Discriminator :: d_loss: 0.628780], [ Generator :: loss: 1.041083]\n",
      "epoch: 35, [Discriminator :: d_loss: 0.668339], [ Generator :: loss: 1.173528]\n",
      "epoch: 36, [Discriminator :: d_loss: 0.841739], [ Generator :: loss: 1.248746]\n",
      "epoch: 37, [Discriminator :: d_loss: 0.706664], [ Generator :: loss: 1.183797]\n",
      "epoch: 38, [Discriminator :: d_loss: 0.618972], [ Generator :: loss: 1.088358]\n",
      "epoch: 39, [Discriminator :: d_loss: 0.742163], [ Generator :: loss: 0.992962]\n",
      "epoch: 40, [Discriminator :: d_loss: 0.723074], [ Generator :: loss: 1.148678]\n",
      "epoch: 41, [Discriminator :: d_loss: 0.677096], [ Generator :: loss: 1.257120]\n",
      "epoch: 42, [Discriminator :: d_loss: 0.609346], [ Generator :: loss: 1.237352]\n",
      "epoch: 43, [Discriminator :: d_loss: 0.682263], [ Generator :: loss: 1.292589]\n",
      "epoch: 44, [Discriminator :: d_loss: 0.563378], [ Generator :: loss: 1.352342]\n",
      "epoch: 45, [Discriminator :: d_loss: 0.764417], [ Generator :: loss: 1.686796]\n",
      "epoch: 46, [Discriminator :: d_loss: 0.756802], [ Generator :: loss: 1.485431]\n",
      "epoch: 47, [Discriminator :: d_loss: 0.629313], [ Generator :: loss: 1.397335]\n",
      "epoch: 48, [Discriminator :: d_loss: 0.696643], [ Generator :: loss: 1.451437]\n",
      "epoch: 49, [Discriminator :: d_loss: 0.623147], [ Generator :: loss: 1.401561]\n",
      "epoch: 50, [Discriminator :: d_loss: 0.747058], [ Generator :: loss: 1.688536]\n",
      "epoch: 51, [Discriminator :: d_loss: 0.561735], [ Generator :: loss: 1.552331]\n",
      "epoch: 52, [Discriminator :: d_loss: 0.586085], [ Generator :: loss: 1.448352]\n",
      "epoch: 53, [Discriminator :: d_loss: 0.598691], [ Generator :: loss: 1.479296]\n",
      "epoch: 54, [Discriminator :: d_loss: 0.636239], [ Generator :: loss: 1.603317]\n",
      "epoch: 55, [Discriminator :: d_loss: 0.761373], [ Generator :: loss: 1.660452]\n",
      "epoch: 56, [Discriminator :: d_loss: 0.546932], [ Generator :: loss: 1.793697]\n",
      "epoch: 57, [Discriminator :: d_loss: 0.581485], [ Generator :: loss: 1.543869]\n",
      "epoch: 58, [Discriminator :: d_loss: 0.598948], [ Generator :: loss: 2.267320]\n",
      "epoch: 59, [Discriminator :: d_loss: 0.535598], [ Generator :: loss: 2.024078]\n",
      "epoch: 60, [Discriminator :: d_loss: 0.635903], [ Generator :: loss: 2.163366]\n",
      "epoch: 61, [Discriminator :: d_loss: 0.546204], [ Generator :: loss: 2.055950]\n",
      "epoch: 62, [Discriminator :: d_loss: 0.593133], [ Generator :: loss: 2.296852]\n",
      "epoch: 63, [Discriminator :: d_loss: 0.497137], [ Generator :: loss: 1.904756]\n",
      "epoch: 64, [Discriminator :: d_loss: 0.548053], [ Generator :: loss: 2.079263]\n",
      "epoch: 65, [Discriminator :: d_loss: 0.596938], [ Generator :: loss: 1.764645]\n",
      "epoch: 66, [Discriminator :: d_loss: 0.631752], [ Generator :: loss: 1.986590]\n",
      "epoch: 67, [Discriminator :: d_loss: 0.563139], [ Generator :: loss: 2.130049]\n",
      "epoch: 68, [Discriminator :: d_loss: 0.570835], [ Generator :: loss: 1.920449]\n",
      "epoch: 69, [Discriminator :: d_loss: 0.586220], [ Generator :: loss: 2.089403]\n",
      "epoch: 70, [Discriminator :: d_loss: 0.573635], [ Generator :: loss: 2.089726]\n",
      "epoch: 71, [Discriminator :: d_loss: 0.608615], [ Generator :: loss: 2.156468]\n",
      "epoch: 72, [Discriminator :: d_loss: 0.695221], [ Generator :: loss: 2.083375]\n",
      "epoch: 73, [Discriminator :: d_loss: 0.561304], [ Generator :: loss: 2.456118]\n",
      "epoch: 74, [Discriminator :: d_loss: 0.684655], [ Generator :: loss: 2.419546]\n",
      "epoch: 75, [Discriminator :: d_loss: 0.646140], [ Generator :: loss: 2.613872]\n",
      "epoch: 76, [Discriminator :: d_loss: 0.501622], [ Generator :: loss: 2.612306]\n",
      "epoch: 77, [Discriminator :: d_loss: 0.561117], [ Generator :: loss: 2.138306]\n",
      "epoch: 78, [Discriminator :: d_loss: 0.724189], [ Generator :: loss: 2.438250]\n",
      "epoch: 79, [Discriminator :: d_loss: 0.582628], [ Generator :: loss: 2.098338]\n",
      "epoch: 80, [Discriminator :: d_loss: 0.505293], [ Generator :: loss: 2.558568]\n",
      "epoch: 81, [Discriminator :: d_loss: 0.609834], [ Generator :: loss: 2.379084]\n",
      "epoch: 82, [Discriminator :: d_loss: 0.639473], [ Generator :: loss: 2.411506]\n",
      "epoch: 83, [Discriminator :: d_loss: 0.603729], [ Generator :: loss: 2.516751]\n",
      "epoch: 84, [Discriminator :: d_loss: 0.616742], [ Generator :: loss: 2.617296]\n",
      "epoch: 85, [Discriminator :: d_loss: 0.515631], [ Generator :: loss: 2.700691]\n",
      "epoch: 86, [Discriminator :: d_loss: 0.618451], [ Generator :: loss: 2.021685]\n",
      "epoch: 87, [Discriminator :: d_loss: 0.657722], [ Generator :: loss: 2.175415]\n",
      "epoch: 88, [Discriminator :: d_loss: 0.569789], [ Generator :: loss: 2.271093]\n",
      "epoch: 89, [Discriminator :: d_loss: 0.563965], [ Generator :: loss: 2.088027]\n",
      "epoch: 90, [Discriminator :: d_loss: 0.548823], [ Generator :: loss: 3.131218]\n",
      "epoch: 91, [Discriminator :: d_loss: 0.586303], [ Generator :: loss: 2.729133]\n",
      "epoch: 92, [Discriminator :: d_loss: 0.473381], [ Generator :: loss: 2.870347]\n",
      "epoch: 93, [Discriminator :: d_loss: 0.517627], [ Generator :: loss: 2.325384]\n",
      "epoch: 94, [Discriminator :: d_loss: 0.587891], [ Generator :: loss: 1.964808]\n",
      "epoch: 95, [Discriminator :: d_loss: 0.536218], [ Generator :: loss: 2.670671]\n",
      "epoch: 96, [Discriminator :: d_loss: 0.519711], [ Generator :: loss: 3.239666]\n",
      "epoch: 97, [Discriminator :: d_loss: 0.501687], [ Generator :: loss: 2.476569]\n",
      "epoch: 98, [Discriminator :: d_loss: 0.559299], [ Generator :: loss: 2.262039]\n",
      "epoch: 99, [Discriminator :: d_loss: 0.568268], [ Generator :: loss: 3.066290]\n",
      "epoch: 100, [Discriminator :: d_loss: 0.548948], [ Generator :: loss: 2.613086]\n",
      "epoch: 101, [Discriminator :: d_loss: 0.571042], [ Generator :: loss: 1.987487]\n",
      "epoch: 102, [Discriminator :: d_loss: 0.595808], [ Generator :: loss: 3.112603]\n",
      "epoch: 103, [Discriminator :: d_loss: 0.609499], [ Generator :: loss: 2.905419]\n",
      "epoch: 104, [Discriminator :: d_loss: 0.536819], [ Generator :: loss: 2.655729]\n",
      "epoch: 105, [Discriminator :: d_loss: 0.540931], [ Generator :: loss: 2.257555]\n",
      "epoch: 106, [Discriminator :: d_loss: 0.666423], [ Generator :: loss: 1.985125]\n",
      "epoch: 107, [Discriminator :: d_loss: 0.614995], [ Generator :: loss: 2.891658]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 108, [Discriminator :: d_loss: 0.515106], [ Generator :: loss: 2.249681]\n",
      "epoch: 109, [Discriminator :: d_loss: 0.496225], [ Generator :: loss: 2.519892]\n",
      "epoch: 110, [Discriminator :: d_loss: 0.544444], [ Generator :: loss: 2.552508]\n",
      "epoch: 111, [Discriminator :: d_loss: 0.601502], [ Generator :: loss: 2.381139]\n",
      "epoch: 112, [Discriminator :: d_loss: 0.527076], [ Generator :: loss: 3.219368]\n",
      "epoch: 113, [Discriminator :: d_loss: 0.465126], [ Generator :: loss: 1.981304]\n",
      "epoch: 114, [Discriminator :: d_loss: 0.598265], [ Generator :: loss: 2.178265]\n",
      "epoch: 115, [Discriminator :: d_loss: 0.481088], [ Generator :: loss: 2.487565]\n",
      "epoch: 116, [Discriminator :: d_loss: 0.522836], [ Generator :: loss: 2.350382]\n",
      "epoch: 117, [Discriminator :: d_loss: 0.569982], [ Generator :: loss: 2.548879]\n",
      "epoch: 118, [Discriminator :: d_loss: 0.531464], [ Generator :: loss: 2.035452]\n",
      "epoch: 119, [Discriminator :: d_loss: 0.522917], [ Generator :: loss: 2.866101]\n",
      "epoch: 120, [Discriminator :: d_loss: 0.523993], [ Generator :: loss: 2.847903]\n",
      "epoch: 121, [Discriminator :: d_loss: 0.591967], [ Generator :: loss: 3.124157]\n",
      "epoch: 122, [Discriminator :: d_loss: 0.477930], [ Generator :: loss: 2.697430]\n",
      "epoch: 123, [Discriminator :: d_loss: 0.579643], [ Generator :: loss: 1.932177]\n",
      "epoch: 124, [Discriminator :: d_loss: 0.507349], [ Generator :: loss: 3.621378]\n",
      "epoch: 125, [Discriminator :: d_loss: 0.512732], [ Generator :: loss: 2.993283]\n",
      "epoch: 126, [Discriminator :: d_loss: 0.494006], [ Generator :: loss: 2.432652]\n",
      "epoch: 127, [Discriminator :: d_loss: 0.515503], [ Generator :: loss: 2.908150]\n",
      "epoch: 128, [Discriminator :: d_loss: 0.580937], [ Generator :: loss: 3.066106]\n",
      "epoch: 129, [Discriminator :: d_loss: 0.489596], [ Generator :: loss: 3.100581]\n",
      "epoch: 130, [Discriminator :: d_loss: 0.533103], [ Generator :: loss: 2.250867]\n",
      "epoch: 131, [Discriminator :: d_loss: 0.512959], [ Generator :: loss: 2.540171]\n",
      "epoch: 132, [Discriminator :: d_loss: 0.528549], [ Generator :: loss: 2.948062]\n",
      "epoch: 133, [Discriminator :: d_loss: 0.550281], [ Generator :: loss: 2.615632]\n",
      "epoch: 134, [Discriminator :: d_loss: 0.604196], [ Generator :: loss: 2.414338]\n",
      "epoch: 135, [Discriminator :: d_loss: 0.525799], [ Generator :: loss: 2.336768]\n",
      "epoch: 136, [Discriminator :: d_loss: 0.527036], [ Generator :: loss: 3.246956]\n",
      "epoch: 137, [Discriminator :: d_loss: 0.513031], [ Generator :: loss: 2.537693]\n",
      "epoch: 138, [Discriminator :: d_loss: 0.506041], [ Generator :: loss: 2.943995]\n",
      "epoch: 139, [Discriminator :: d_loss: 0.522968], [ Generator :: loss: 2.234942]\n",
      "epoch: 140, [Discriminator :: d_loss: 0.580427], [ Generator :: loss: 2.105329]\n",
      "epoch: 141, [Discriminator :: d_loss: 0.521331], [ Generator :: loss: 3.158686]\n",
      "epoch: 142, [Discriminator :: d_loss: 0.489046], [ Generator :: loss: 2.063759]\n",
      "epoch: 143, [Discriminator :: d_loss: 0.458051], [ Generator :: loss: 2.781624]\n",
      "epoch: 144, [Discriminator :: d_loss: 0.507933], [ Generator :: loss: 2.402165]\n",
      "epoch: 145, [Discriminator :: d_loss: 0.533758], [ Generator :: loss: 2.507633]\n",
      "epoch: 146, [Discriminator :: d_loss: 0.468946], [ Generator :: loss: 1.591077]\n",
      "epoch: 147, [Discriminator :: d_loss: 0.611467], [ Generator :: loss: 2.719795]\n",
      "epoch: 148, [Discriminator :: d_loss: 0.496565], [ Generator :: loss: 3.077705]\n",
      "epoch: 149, [Discriminator :: d_loss: 0.519144], [ Generator :: loss: 3.062503]\n",
      "epoch: 150, [Discriminator :: d_loss: 0.573812], [ Generator :: loss: 3.527130]\n",
      "epoch: 151, [Discriminator :: d_loss: 0.511860], [ Generator :: loss: 2.697703]\n",
      "epoch: 152, [Discriminator :: d_loss: 0.510377], [ Generator :: loss: 2.707136]\n",
      "epoch: 153, [Discriminator :: d_loss: 0.554987], [ Generator :: loss: 2.451518]\n",
      "epoch: 154, [Discriminator :: d_loss: 0.484442], [ Generator :: loss: 2.357547]\n",
      "epoch: 155, [Discriminator :: d_loss: 0.500146], [ Generator :: loss: 2.925248]\n",
      "epoch: 156, [Discriminator :: d_loss: 0.564809], [ Generator :: loss: 2.608766]\n",
      "epoch: 157, [Discriminator :: d_loss: 0.543597], [ Generator :: loss: 3.398434]\n",
      "epoch: 158, [Discriminator :: d_loss: 0.543962], [ Generator :: loss: 2.411216]\n",
      "epoch: 159, [Discriminator :: d_loss: 0.530501], [ Generator :: loss: 2.455159]\n",
      "epoch: 160, [Discriminator :: d_loss: 0.585011], [ Generator :: loss: 1.776878]\n",
      "epoch: 161, [Discriminator :: d_loss: 0.540625], [ Generator :: loss: 2.647986]\n",
      "epoch: 162, [Discriminator :: d_loss: 0.524593], [ Generator :: loss: 3.009691]\n",
      "epoch: 163, [Discriminator :: d_loss: 0.505340], [ Generator :: loss: 3.197288]\n",
      "epoch: 164, [Discriminator :: d_loss: 0.549635], [ Generator :: loss: 2.624807]\n",
      "epoch: 165, [Discriminator :: d_loss: 0.521193], [ Generator :: loss: 3.164907]\n",
      "epoch: 166, [Discriminator :: d_loss: 0.516840], [ Generator :: loss: 2.923987]\n",
      "epoch: 167, [Discriminator :: d_loss: 0.512182], [ Generator :: loss: 2.352127]\n",
      "epoch: 168, [Discriminator :: d_loss: 0.516355], [ Generator :: loss: 3.073073]\n",
      "epoch: 169, [Discriminator :: d_loss: 0.518117], [ Generator :: loss: 3.292814]\n",
      "epoch: 170, [Discriminator :: d_loss: 0.505980], [ Generator :: loss: 2.018647]\n",
      "epoch: 171, [Discriminator :: d_loss: 0.488070], [ Generator :: loss: 2.490908]\n",
      "epoch: 172, [Discriminator :: d_loss: 0.527061], [ Generator :: loss: 2.371628]\n",
      "epoch: 173, [Discriminator :: d_loss: 0.495712], [ Generator :: loss: 2.676414]\n",
      "epoch: 174, [Discriminator :: d_loss: 0.532561], [ Generator :: loss: 2.802367]\n",
      "epoch: 175, [Discriminator :: d_loss: 0.521480], [ Generator :: loss: 2.601005]\n",
      "epoch: 176, [Discriminator :: d_loss: 0.509638], [ Generator :: loss: 2.103580]\n",
      "epoch: 177, [Discriminator :: d_loss: 0.549147], [ Generator :: loss: 1.745737]\n",
      "epoch: 178, [Discriminator :: d_loss: 0.516852], [ Generator :: loss: 2.893099]\n",
      "epoch: 179, [Discriminator :: d_loss: 0.518253], [ Generator :: loss: 2.881971]\n",
      "epoch: 180, [Discriminator :: d_loss: 0.498071], [ Generator :: loss: 2.051912]\n",
      "epoch: 181, [Discriminator :: d_loss: 0.486806], [ Generator :: loss: 2.374708]\n",
      "epoch: 182, [Discriminator :: d_loss: 0.517050], [ Generator :: loss: 2.892036]\n",
      "epoch: 183, [Discriminator :: d_loss: 0.512400], [ Generator :: loss: 1.720587]\n",
      "epoch: 184, [Discriminator :: d_loss: 0.480132], [ Generator :: loss: 2.041099]\n",
      "epoch: 185, [Discriminator :: d_loss: 0.501176], [ Generator :: loss: 2.707102]\n",
      "epoch: 186, [Discriminator :: d_loss: 0.538942], [ Generator :: loss: 2.418618]\n",
      "epoch: 187, [Discriminator :: d_loss: 0.536035], [ Generator :: loss: 1.618937]\n",
      "epoch: 188, [Discriminator :: d_loss: 0.446985], [ Generator :: loss: 2.672453]\n",
      "epoch: 189, [Discriminator :: d_loss: 0.490079], [ Generator :: loss: 2.484632]\n",
      "epoch: 190, [Discriminator :: d_loss: 0.497059], [ Generator :: loss: 1.715584]\n",
      "epoch: 191, [Discriminator :: d_loss: 0.493670], [ Generator :: loss: 1.543637]\n",
      "epoch: 192, [Discriminator :: d_loss: 0.503437], [ Generator :: loss: 3.343887]\n",
      "epoch: 193, [Discriminator :: d_loss: 0.473719], [ Generator :: loss: 2.061451]\n",
      "epoch: 194, [Discriminator :: d_loss: 0.539372], [ Generator :: loss: 2.285963]\n",
      "epoch: 195, [Discriminator :: d_loss: 0.472647], [ Generator :: loss: 2.072448]\n",
      "epoch: 196, [Discriminator :: d_loss: 0.505551], [ Generator :: loss: 1.914044]\n",
      "epoch: 197, [Discriminator :: d_loss: 0.494362], [ Generator :: loss: 2.103292]\n",
      "epoch: 198, [Discriminator :: d_loss: 0.490371], [ Generator :: loss: 1.662064]\n",
      "epoch: 199, [Discriminator :: d_loss: 0.526413], [ Generator :: loss: 2.061003]\n"
     ]
    }
   ],
   "source": [
    "train(malicious, normal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preidiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.clip(0.999, 0.001,np.concatenate((malicious, normal)))\n",
    "y = np.concatenate((np.ones((100, 1)), np.zeros((100, 1))))\n",
    "predict = discriminator.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5297213 , 0.5260311 , 0.4552513 , 0.29114658, 0.519302  ,\n",
       "       0.4838573 , 0.5261893 , 0.5146875 , 0.5209128 , 0.5449027 ,\n",
       "       0.42899117, 0.48511767, 0.522623  , 0.33279607, 0.3898391 ,\n",
       "       0.5271429 , 0.3746858 , 0.5239943 , 0.5393062 , 0.5429988 ,\n",
       "       0.5301274 , 0.52228695, 0.35519844, 0.5498112 , 0.54116607,\n",
       "       0.5407401 , 0.55221134, 0.53330934, 0.47260338, 0.54400885,\n",
       "       0.5284057 , 0.43215245, 0.5159782 , 0.50539315, 0.44561556,\n",
       "       0.46921915, 0.4521281 , 0.5282074 , 0.545667  , 0.53650296,\n",
       "       0.5350041 , 0.37155318, 0.51021665, 0.52935493, 0.4151826 ,\n",
       "       0.43897268, 0.53847873, 0.45460096, 0.3442491 , 0.40009287,\n",
       "       0.53334224, 0.42708474, 0.44393903, 0.4421928 , 0.4656596 ,\n",
       "       0.459181  , 0.42023203, 0.39834163, 0.48070705, 0.4718846 ,\n",
       "       0.53320104, 0.534909  , 0.53406346, 0.39340568, 0.43232605,\n",
       "       0.31525916, 0.48846745, 0.43380564, 0.55039626, 0.44425356,\n",
       "       0.5407282 , 0.51611286, 0.54152393, 0.42778778, 0.4789627 ,\n",
       "       0.5463469 , 0.47998106, 0.43933135, 0.43290266, 0.5518433 ,\n",
       "       0.5284927 , 0.49973932, 0.56147224, 0.4127951 , 0.5406343 ,\n",
       "       0.53691566, 0.54987735, 0.52879906, 0.531734  , 0.45933756,\n",
       "       0.5390097 , 0.5446935 , 0.48223993, 0.38795698, 0.32044116,\n",
       "       0.5403815 , 0.43925154, 0.5087499 , 0.31834713, 0.44605702,\n",
       "       0.5174529 , 0.4203909 , 0.41239908, 0.4722103 , 0.52157074,\n",
       "       0.4329419 , 0.3312272 , 0.379998  , 0.39068657, 0.41119346,\n",
       "       0.34258333, 0.4374741 , 0.3658088 , 0.40060884, 0.40852958,\n",
       "       0.4564743 , 0.40841126, 0.32478768, 0.5015988 , 0.40566844,\n",
       "       0.46198454, 0.45850497, 0.5032314 , 0.49265262, 0.5046213 ,\n",
       "       0.44148278, 0.38008428, 0.42482004, 0.25221524, 0.41930845,\n",
       "       0.42551547, 0.35880768, 0.3638685 , 0.29006022, 0.4756551 ,\n",
       "       0.33834827, 0.20268217, 0.35194498, 0.5359861 , 0.42794523,\n",
       "       0.40717223, 0.47710583, 0.3367352 , 0.38583055, 0.4661471 ,\n",
       "       0.501366  , 0.4601713 , 0.45885885, 0.46353266, 0.41731697,\n",
       "       0.41094142, 0.516428  , 0.4190688 , 0.3314082 , 0.5419767 ,\n",
       "       0.54048437, 0.5229455 , 0.42623875, 0.3693232 , 0.3970446 ,\n",
       "       0.48700938, 0.52355593, 0.47592622, 0.2604021 , 0.3979246 ,\n",
       "       0.43560746, 0.45841667, 0.39188102, 0.4817876 , 0.46100128,\n",
       "       0.3081801 , 0.3426705 , 0.2915237 , 0.48358357, 0.41072324,\n",
       "       0.47953898, 0.4279931 , 0.47157437, 0.41744322, 0.5223424 ,\n",
       "       0.34735546, 0.5307697 , 0.35820264, 0.43077004, 0.4143638 ,\n",
       "       0.39057043, 0.33795294, 0.5188762 , 0.3562621 , 0.42743358,\n",
       "       0.40282035, 0.38283846, 0.36767486, 0.4293866 , 0.35185254,\n",
       "       0.4067847 , 0.45019153, 0.3616108 , 0.3944935 , 0.4821265 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y == (predict > 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
